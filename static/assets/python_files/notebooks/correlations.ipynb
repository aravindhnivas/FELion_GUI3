{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path as pt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.widgets import SpanSelector\n",
    "from ipywidgets import widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_func(x, A, sig, mu): return A*np.exp(-1/2 * ((x-mu)/sig)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_simulation(freq_range, original_signal, corr_collection, sim_range, title=\"\"):\n",
    "    %matplotlib widget\n",
    "    plt.close(\"all\")\n",
    "    fig = plt.figure(tight_layout=True, figsize=(12, 7))\n",
    "    gs = gridspec.GridSpec(2, 2)\n",
    "\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "    ax1 = fig.add_subplot(gs[0, 1])\n",
    "    ax2 = fig.add_subplot(gs[1, :])\n",
    "    \n",
    "    ax.plot(freq_range, original_signal.T,  \".\")\n",
    "    ax.legend([\"Res OFF\", \"Res ON\"])\n",
    "    \n",
    "    res_off_background, res_on_signal = original_signal\n",
    "    original_signal_depletion = (1 - (res_on_signal/res_off_background))*100\n",
    "    \n",
    "    depletion_line, = ax1.plot(freq_range, original_signal_depletion,  \".k\")\n",
    "    ax1.legend([f\"Signal (%)\"])\n",
    "    \n",
    "    ax2.plot(sim_range, corr_collection, \".-\")\n",
    "    \n",
    "    corr_collection = corr_collection.T\n",
    "    corr_diff = corr_collection[0] - corr_collection[1]\n",
    "    \n",
    "    ax2.legend([f\"Background corr. {corr_collection[0].mean():.2f}({corr_collection[0].std():.2f})\",\\\n",
    "                f\"Signal corr. {corr_collection[1].mean():.2f}({corr_collection[1].std():.2f})\"],\\\n",
    "              title=f\"Corr. diff: {corr_diff.mean():.2f}({corr_diff.std():.2f})\")\n",
    "    \n",
    "    ax.set(title=f\"{title} Experimental data\", xlabel=\"Frequency (MHz)\", ylabel=\"Counts\")\n",
    "    ax1.set(title=f\"{title} Experimental data\", xlabel=\"Frequency (MHz)\", ylabel=\"Depletion (%)\")\n",
    "    \n",
    "    corr_title = \"Positive Corrleation\" if corr_diff.mean() > 0 else \"Negative Corrleation\"\n",
    "    ax2.set(xlabel=\"Simulation No. (#)\", ylabel=\"Correlation factor (r)\", title=corr_title)\n",
    "    \n",
    "    for _ in (ax, ax1, ax2):\n",
    "        _.minorticks_on()\n",
    "        _.grid()\n",
    "    \n",
    "    def onselect(xmin, xmax):\n",
    "        indmin, indmax = np.searchsorted(original_signal_depletion, (xmin, xmax))\n",
    "        indmax = min(len(x) - 1, indmax)\n",
    "\n",
    "        thisx = freq_range[indmin:indmax]\n",
    "        thisy = original_signal_depletion[indmin:indmax]\n",
    "        depletion_line.set_data(thisx, thisy)\n",
    "        ax.set_xlim(thisx[0], thisx[-1])\n",
    "        ax.set_ylim(thisy.min(), thisy.max())\n",
    "        \n",
    "        ax1.set_xlim(thisx[0], thisx[-1])\n",
    "        ax1.set_ylim(thisy.min(), thisy.max())\n",
    "        \n",
    "        fig.canvas.draw()\n",
    "\n",
    "    span = SpanSelector(ax1, onselect, 'horizontal', useblit=True,\n",
    "                        rectprops=dict(alpha=0.5, facecolor='red'))\n",
    "    plt.show()\n",
    "    \n",
    "def get_lineshape(base_counts, mu, freq_range, fwhm, A):\n",
    "    \n",
    "    fwhm = fwhm*1e-3 # FWHM in MHz\n",
    "    sig = fwhm/(2*np.sqrt(2*np.log(2))) # Sigma in MHz\n",
    "    A = -(A/100)*base_counts # Intensity\n",
    "    \n",
    "    signal_shape = gauss_func(freq_range, A, sig, mu)\n",
    "    \n",
    "    return signal_shape\n",
    "\n",
    "def get_noise(noise, corr_ratio, freq_range, base_counts):\n",
    "    \n",
    "    corr_noise_sig = corr_ratio*noise\n",
    "    corr_noise = np.random.normal(0, corr_noise_sig, freq_range.shape)\n",
    "    \n",
    "    noise_sig = (1-corr_ratio)*noise\n",
    "    \n",
    "    res_off_background = np.random.normal(base_counts, noise_sig, freq_range.shape) + corr_noise\n",
    "    res_on_background = np.random.normal(base_counts, noise_sig, freq_range.shape) + corr_noise\n",
    "    random_noise = np.random.normal(base_counts, noise_sig, freq_range.shape) + corr_noise\n",
    "    \n",
    "    return res_off_background, res_on_background, random_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828dcaebc52949a984c4e11c64b811e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=100, description='noise', max=300, min=-100), FloatSlider(value=0.6, des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@widgets.interact_manual()\n",
    "def simulate_correlation(noise=100, corr_ratio=0.6, sim_range=50, base_counts=1000, start_freq=1, end_freq=5, step_size=10, A=10, fwhm=500, mu=1.5, plot=True):\n",
    "\n",
    "    # Defining frequency range\n",
    "    step_size = step_size*1e-3 # KHz\n",
    "\n",
    "    freq_range = np.arange(start_freq, end_freq, step_size)\n",
    "\n",
    "    # Background counts with noise\n",
    "    res_off_background, res_on_background, random_noise = get_noise(noise, corr_ratio, freq_range, base_counts)\n",
    "    \n",
    "    # Calculating signal shape (Gaussian distribution)\n",
    "    signal_shape = get_lineshape(base_counts, mu, freq_range, fwhm, A)\n",
    "    \n",
    "    # res_on_background = np.random.normal(base_counts, noise_sig, freq_range.shape)\n",
    "    res_on_signal = signal_shape + res_on_background\n",
    "\n",
    "    original_signal = np.array([res_off_background, res_on_signal])\n",
    "\n",
    "    # Calculating correlation factor by running several number of simulations\n",
    "    corr_collection = []\n",
    "    sim_range = np.arange(sim_range)\n",
    "\n",
    "    for _ in sim_range:\n",
    "        \n",
    "        res_off_background, res_on_background, random_noise = get_noise(noise, corr_ratio, freq_range, base_counts)\n",
    "        \n",
    "        res_on_signal = signal_shape + random_noise\n",
    "\n",
    "        correlation_noise = np.corrcoef(res_off_background, res_on_background)[0, 1]\n",
    "        correlation_sig = np.corrcoef(res_off_background, res_on_signal)[0, 1]\n",
    "        \n",
    "        corr_collection.append([correlation_noise, correlation_sig])\n",
    "\n",
    "    corr_collection = np.array(corr_collection)\n",
    "    \n",
    "    if plot: plot_simulation(freq_range, original_signal, corr_collection, sim_range, title=\"Simulating\")\n",
    "    else: \n",
    "        return corr_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b4d95e2ea16496f858a9d688203b98c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='A', max=30, min=-10), IntSlider(value=500, description=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@widgets.interact_manual(A=10, fwhm=500, mu=3, noise_sig=50, extra_noise_sig=2, sim_range=\"5\", base_counts=1000, start_freq=\"1\", end_freq=\"5\", step_size=\"10\", _from=\"1\", _to=\"10\", _step=\"1\", variable=\"fwhm\")\n",
    "def simulate_correlation_fwhm(A, fwhm, mu, noise_sig, extra_noise_sig, sim_range, base_counts=1000, start_freq=\"1\", end_freq=\"5\", step_size=\"10\", _from=\"1\", _to=\"10\", _step=\"1\", variable=\"fwhm\"):\n",
    "    \n",
    "    variable_list = {\n",
    "        \"A\":A, \"fwhm\":fwhm, \"noise_sig\":noise_sig, \"step_size\":step_size, \"mu\":mu,\n",
    "        \"extra_noise_sig\":extra_noise_sig, \"sim_range\":int(sim_range),\n",
    "        \"start_freq\":int(start_freq), \"end_freq\":int(step_size), \"step_size\":int(step_size),\n",
    "        \"base_counts\":base_counts,\n",
    "        \"plot\":False\n",
    "    }\n",
    "    \n",
    "    variable_range = np.arange(int(_from), int(_to), float(_step))\n",
    "    \n",
    "    datas = []\n",
    "    \n",
    "    for _ in variable_range:\n",
    "        variable_list[variable] = _\n",
    "        temp = simulate_correlation(**variable_list)\n",
    "        datas.append(temp)\n",
    "\n",
    "    datas = np.array(datas).T\n",
    "    freq_range, corr_collection = datas\n",
    "    \n",
    "    corr_diff_collection = []\n",
    "    for corr in corr_collection:\n",
    "        corr = corr.T\n",
    "        corr_diff = corr[0] - corr[1]\n",
    "        corr_diff = corr_diff.mean()\n",
    "        corr_diff_collection.append(corr_diff)\n",
    "    \n",
    "    corr_diff_collection = np.array(corr_diff_collection)\n",
    "    \n",
    "    %matplotlib widget\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(variable_range.T, corr_diff_collection.T, \".-\")\n",
    "    \n",
    "    ax.set(title=f\"Correlation difference as a function of {variable}\", xlabel=variable, ylabel=\"Correlation factor difference\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from widgetDefinitions import createWidgets\n",
    "thz_widget = createWidgets(filetype=\"thz\", multiselect=True, locationValue=r\"D:\\Measurements\\THz\\CO+\\thz\\117\")\n",
    "thz_widget.files.layout.height = \"300px\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thz_plot(location, filename):\n",
    "\n",
    "    location = pt(location)\n",
    "    \n",
    "    with open(location/filename, \"r\") as fileContents: file = fileContents.readlines()\n",
    "\n",
    "    file = file[1:]\n",
    "    resOn = []\n",
    "\n",
    "    for line in file:\n",
    "        if line.startswith(\"#\"): break\n",
    "        line = line.split(\"\\n\")[0].split(\"\\t\")[:-1]\n",
    "        if not \"0\" in line: resOn.append(line)\n",
    "    resOn = resOn[1:]\n",
    "\n",
    "    resOff = []\n",
    "    start = False\n",
    "\n",
    "    for line in file:\n",
    "        if line.startswith(\"# freq\"):\n",
    "            start = True\n",
    "            continue\n",
    "        if start: \n",
    "            if line.startswith(\"#\"): break\n",
    "            line = line.split(\"\\n\")[0].split(\"\\t\")[:-1]\n",
    "            if not \"0\" in line: resOff.append(line)\n",
    "            \n",
    "    resOff = resOff[1:]\n",
    "    #############################################\n",
    "\n",
    "    # print(f\"{resOn}\\n{resOff}\")\n",
    "    resOn = np.array(resOn, dtype=float)\n",
    "    resOff = np.array(resOff, dtype=float)\n",
    "    #############################################\n",
    "\n",
    "    freq = resOn.T[0]\n",
    "    freq_resOff = resOff.T[0][0]\n",
    "    depletion = (resOff.T[1:] - resOn.T[1:])/resOff.T[1:]\n",
    "    depletion_counts = depletion.T.mean(axis=1)\n",
    "\n",
    "    # depletion_error = depletion.T.std(axis=1)*100\n",
    "\n",
    "    depletion_counts = depletion_counts*100\n",
    "\n",
    "    iteraton = int(len(resOn[0, 1:]))\n",
    "    steps = int(round((freq[1]-freq[0])*1e6, 0))\n",
    "\n",
    "    resOffCounts, resOnCounts = resOff.T[1:], resOn.T[1:]\n",
    "\n",
    "    return freq, depletion_counts, steps, iteraton, resOffCounts, resOnCounts, freq_resOff\n",
    "\n",
    "        \n",
    "def get_noise_experiment(resOffCounts, resOnCounts, corr_noise):\n",
    "    \n",
    "    res_off_background = resOffCounts + corr_noise\n",
    "    \n",
    "    base_counts = resOffCounts.mean()\n",
    "    base_std = resOffCounts.std()\n",
    "    res_on_background = np.random.normal(base_counts, base_std, resOnCounts.shape) + corr_noise\n",
    "    \n",
    "    return res_off_background, res_on_background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binning(xs, ys, delta=1e-5):\n",
    "\n",
    "    \"\"\"\n",
    "    Binns the data provided in xs and ys to bins of width delta\n",
    "    output: binns, intensity \n",
    "    \"\"\"\n",
    "\n",
    "    # bins = np.arange(start, end, delta)\n",
    "    # occurance = np.zeros(start, end, delta)\n",
    "    BIN_STEP = delta\n",
    "    BIN_START = xs.min()\n",
    "    BIN_STOP = xs.max()\n",
    "\n",
    "    indices = xs.argsort()\n",
    "    datax = xs[indices]\n",
    "    datay = ys[indices]\n",
    "\n",
    "    # print(\"In total we have: \", len(datax), ' data points.')\n",
    "    # do the binning of the data\n",
    "    bins = np.arange(BIN_START, BIN_STOP, BIN_STEP)\n",
    "    # print(\"Binning starts: \", BIN_START,\n",
    "    #    ' with step: ', BIN_STEP, ' ENDS: ', BIN_STOP)\n",
    "\n",
    "    bin_i = np.digitize(datax, bins)\n",
    "    bin_a = np.zeros(len(bins) + 1)\n",
    "    bin_occ = np.zeros(len(bins) + 1)\n",
    "\n",
    "    for i in range(datay.size):\n",
    "        bin_a[bin_i[i]] += datay[i]\n",
    "        bin_occ[bin_i[i]] += 1\n",
    "\n",
    "    binsx, data_binned = [], []\n",
    "    for i in range(bin_occ.size - 1):\n",
    "\n",
    "        if bin_occ[i] > 0:\n",
    "            binsx.append(bins[i] - BIN_STEP / 2)\n",
    "            data_binned.append(bin_a[i] / bin_occ[i])\n",
    "\n",
    "    # non_zero_i = bin_occ > 0\n",
    "    # binsx = bins[non_zero_i] - BIN_STEP/2\n",
    "    # data_binned = bin_a[non_zero_i]/bin_occ[non_zero_i]\n",
    "    # print(\"after binning\", binsx, data_binned)\n",
    "    binsx = np.array(binsx, dtype=float)\n",
    "\n",
    "    data_binned = np.array(data_binned, dtype=float)\n",
    "    return binsx, data_binned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a7d809499d47bba259c3538e515392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='update location', layout=Layout(width='20%'), style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f4fa838d284377918aa87bb78f3006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='\\\\\\\\felixdisk.science.ru.nl\\\\felixshare2\\\\22pole_iontrap-exchange\\\\Students\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(thz_widget.update_files_button)\n",
    "\n",
    "@widgets.interact_manual(location=thz_widget.location, filename=thz_widget.files, ind=\"-1\", corr_ratio=0.6, sim_range=50, plot=True)\n",
    "def thz_experiment_dat(location, filename, ind, corr_ratio, sim_range, plot=True):\n",
    "    \n",
    "    ind = int(ind)\n",
    "    \n",
    "    freq_collection = []\n",
    "    resOffCollection = []\n",
    "    resOnCollection = []\n",
    "    \n",
    "    for f in filename:\n",
    "        freq, depletion_counts, steps, iteraton, resOffCounts, resOnCounts, freq_resOff = thz_plot(location, f)\n",
    "        \n",
    "        resOffCounts = resOffCounts.mean(axis=0)\n",
    "        resOnCounts = resOnCounts.mean(axis=0)\n",
    "        \n",
    "        freq_collection = np.append(freq_collection, freq)\n",
    "        \n",
    "        # normalising\n",
    "        maxCounts_off = resOffCounts.max()\n",
    "        norm = 100/maxCounts_off\n",
    "        resOffCounts = resOffCounts*norm\n",
    "        resOffCollection = np.append(resOffCollection, resOffCounts)\n",
    "        \n",
    "        maxCounts_on = resOnCounts.max()\n",
    "        norm = 100/maxCounts_on\n",
    "        resOnCounts = resOnCounts*norm\n",
    "        resOnCollection = np.append(resOnCollection, resOnCounts)\n",
    "    \n",
    "    freq, resOffCounts = binning(freq_collection, resOffCollection)\n",
    "    freq, resOnCounts = binning(freq_collection, resOnCollection)\n",
    "    \n",
    "    original_signal = np.array([resOffCounts, resOnCounts])\n",
    "    \n",
    "    noise_sig = resOffCounts.std()\n",
    "    print(f\"Total points: {resOffCounts.size}\")\n",
    "    \n",
    "    total_noise = noise_sig/(1 - corr_ratio)\n",
    "    corr_noise_sig = total_noise - noise_sig\n",
    "    \n",
    "    print(f\"{noise_sig=:.2f}\\n{total_noise=:.2f}\\n{corr_noise_sig=:.2f}\")\n",
    "    \n",
    "    # Calculating correlation factor by running several number of simulations\n",
    "    corr_collection = []\n",
    "    sim_range = np.arange(sim_range)\n",
    "\n",
    "    for _ in sim_range:\n",
    "\n",
    "        corr_noise = np.random.normal(0, corr_noise_sig, freq.shape)\n",
    "        res_off_background, res_on_background = get_noise_experiment(resOffCounts, resOnCounts, corr_noise)\n",
    "\n",
    "        res_on_signal = resOnCounts + corr_noise\n",
    "\n",
    "        correlation_noise = np.corrcoef(res_off_background[:ind], res_on_background[:ind])[0, 1]\n",
    "        correlation_sig = np.corrcoef(res_off_background, res_on_signal)[0, 1]\n",
    "\n",
    "        corr_collection.append([correlation_noise, correlation_sig])\n",
    "\n",
    "    corr_collection = np.array(corr_collection)\n",
    "    \n",
    "    if plot: plot_simulation(freq, original_signal, corr_collection, sim_range)\n",
    "    else: \n",
    "        return corr_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
